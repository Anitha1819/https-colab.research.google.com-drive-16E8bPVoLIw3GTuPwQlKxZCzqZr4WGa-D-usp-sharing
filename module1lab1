{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anitha1819/https-colab.research.google.com-drive-16E8bPVoLIw3GTuPwQlKxZCzqZr4WGa-D-usp-sharing/blob/main/module1lab1\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6I1yI79fbLD"
      },
      "source": [
        "# Extracting features from data\n",
        "\n",
        "FMML Module 1, Lab 1<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OimBnfcpvcNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e1964c1-cb43-45ec-cd7f-f1283c092dcd"
      },
      "source": [
        "! pip install wikipedia\n",
        "\n",
        "import wikipedia\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "import plotly.express as px\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.11.17)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=24755a5d58a92e8aa084de6a59036de356a958eb458a47b69032fe70e8ea1551\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6hGhIGiy4GP"
      },
      "source": [
        "# Part 1: Features of text\n",
        "How do we apply machine learning on text? We can't directly use the text as input to our algorithms. We need to convert them to features. In this notebook, we will explore a simple way of converting text to features.\n",
        "\n",
        "Let us download a few documents off Wikipedia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpUmCoEr2R3J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "ce8b5897-a01a-4d7d-ab33-a668245c3b34"
      },
      "source": [
        "topic1 = 'Giraffe'\n",
        "topic2 = 'Elephant'\n",
        "\n",
        "wikipedia.set_lang('en')\n",
        "\n",
        "eng1 = wikipedia.page(topic1).content\n",
        "eng2 = wikipedia.page(topic2).content\n",
        "\n",
        "wikipedia.set_lang('fr')\n",
        "\n",
        "fr1 = wikipedia.page(topic1).content\n",
        "fr2 = wikipedia.page(topic2).content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "WikipediaException",
          "evalue": "An unknown error occured: \"Search is currently too busy. Please try again later.\". Please report it on GitHub!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWikipediaException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bc2d66e35c9d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0meng1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0meng2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36mpage\u001b[0;34m(title, pageid, auto_suggest, redirect, preload)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauto_suggest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m       \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuggestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuggestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuggestion\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wikipedia/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(query, results, suggestion)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mHTTPTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mWikipediaException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'search'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWikipediaException\u001b[0m: An unknown error occured: \"Search is currently too busy. Please try again later.\". Please report it on GitHub!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj7RlhMiO5kd"
      },
      "source": [
        "This is what the text looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW0G-t912UXZ"
      },
      "source": [
        "fr2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZkmNJ7XO9xX"
      },
      "source": [
        "We need to clean this up a bit. Let us remove all the special characters and keep only 26 letters and space. Note that this will remove accented characters in French also. We are also removing all the numbers and spaces. So this is not an ideal solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5yf5P9pPI4t"
      },
      "source": [
        "def cleanup(text):\n",
        "  text = text.lower()  # make it lowercase\n",
        "  text = re.sub('[^a-z]+', '', text) # only keep characters\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrOjC32fRuTK"
      },
      "source": [
        "eng1 = cleanup(eng1)\n",
        "eng2 = cleanup(eng2)\n",
        "fr1 = cleanup(fr1)\n",
        "fr2 = cleanup(fr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIdqvL2G-LqL"
      },
      "source": [
        "print(eng1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXFTWwd0rk63"
      },
      "source": [
        "Now let us calculate the frequency of the character n-grams. N-grams are groups of characters of size n. A unigram is a single character and a bigram is a group of two characters and so on.\n",
        "\n",
        "Let us count the frequency of each character in a text and plot it in a histogram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Lz3YUjN0L5"
      },
      "source": [
        "# convert a tuple of characters to a string\n",
        "def tuple2string(tup):\n",
        "  st = ''\n",
        "  for ii in tup:\n",
        "    st = st + ii\n",
        "  return st\n",
        "\n",
        "# convert a tuple of tuples to a list of strings\n",
        "def key2string(keys):\n",
        "  return [tuple2string(i) for i in keys]\n",
        "\n",
        "# plot the histogram\n",
        "def plothistogram(ngram):\n",
        "  keys = key2string(ngram.keys())\n",
        "  values = list(ngram.values())\n",
        "\n",
        "  # sort the keys in alphabetic order\n",
        "  combined = zip(keys, values)\n",
        "  zipped_sorted = sorted(combined, key=lambda x: x[0])\n",
        "  keys, values = map(list, zip(*zipped_sorted))\n",
        "  plt.bar(keys, values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHD62zbZcwAB"
      },
      "source": [
        "Let us compare the histograms of English pages and French pages. Can you spot a difference?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKcGRgH6b0KP"
      },
      "source": [
        "unigram_eng1 = Counter(ngrams(eng1,1))\n",
        "plothistogram(unigram_eng1)\n",
        "plt.title('English 1')\n",
        "plt.show()\n",
        "unigram_eng2 = Counter(ngrams(eng2,1))\n",
        "plothistogram(unigram_eng2)\n",
        "plt.title('English 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDM_UhCL2QLt"
      },
      "source": [
        "unigram_fr1 = Counter(ngrams(fr1,1))\n",
        "plothistogram(unigram_eng1)\n",
        "plt.title('French 1')\n",
        "plt.show()\n",
        "unigram_fr2 = Counter(ngrams(fr2,1))\n",
        "plothistogram(unigram_fr2)\n",
        "plt.title('French 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxgrdZLKdkAB"
      },
      "source": [
        "We can see that the unigrams for French and English are very similar. So this is not a good feature if we want to distinguish between English and French. Let us look at bigrams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmRCxItx2T9W"
      },
      "source": [
        "bigram_eng1 = Counter(ngrams(eng1,2)) # bigrams\n",
        "plothistogram(bigram_eng1)\n",
        "plt.title('English 1')\n",
        "plt.show()\n",
        "\n",
        "bigram_eng2 = Counter(ngrams(eng2,2))\n",
        "plothistogram(bigram_eng2)\n",
        "plt.title('English 2')\n",
        "plt.show()\n",
        "\n",
        "bigram_fr1 = Counter(ngrams(fr1,2))\n",
        "plothistogram(bigram_eng1)\n",
        "plt.title('French 1')\n",
        "plt.show()\n",
        "\n",
        "bigram_fr2 = Counter(ngrams(fr2,2))\n",
        "plothistogram(bigram_fr2)\n",
        "plt.title('French 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-egsHMIg5Rp"
      },
      "source": [
        "Another way to visualize bigrams is to use a 2-dimensional graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EaPJgtaVxZM"
      },
      "source": [
        "def plotbihistogram(ngram):\n",
        "  freq = np.zeros((26,26))\n",
        "  for ii in range(26):\n",
        "    for jj in range(26):\n",
        "      freq[ii,jj] = ngram[(chr(ord('a')+ii), chr(ord('a')+jj))]\n",
        "  plt.imshow(freq, cmap = 'jet')\n",
        "  return freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7jq3AwnVzQT"
      },
      "source": [
        "bieng1 = plotbihistogram(bigram_eng1)\n",
        "plt.show()\n",
        "bieng2 = plotbihistogram(bigram_eng2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXPTOj67WsPT"
      },
      "source": [
        "bifr1 = plotbihistogram(bigram_fr1)\n",
        "plt.show()\n",
        "bifr2 = plotbihistogram(bigram_fr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGOEHcyGokD0"
      },
      "source": [
        "Let us look at the top 10 ngrams for each text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk2TkzTno8vb"
      },
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "def ind2tup(ind):\n",
        "  ind = int(ind)\n",
        "  i = int(ind/26)\n",
        "  j = int(ind%26)\n",
        "  return (chr(ord('a')+i), chr(ord('a')+j))\n",
        "\n",
        "def ShowTopN(bifreq, n=10):\n",
        "  f = bifreq.flatten()\n",
        "  arg = np.argsort(-f)\n",
        "  for ii in range(n):\n",
        "    print(f'{ind2tup(arg[ii])} : {f[arg[ii]]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HeWNh_q0QZ1"
      },
      "source": [
        "print('\\nEnglish 1:')\n",
        "ShowTopN(bieng1)\n",
        "print('\\nEnglish 2:')\n",
        "ShowTopN(bieng2)\n",
        "print('\\nFrench 1:')\n",
        "ShowTopN(bifr1)\n",
        "print('\\nFrench 2:')\n",
        "ShowTopN(bifr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kDovOP4l98z"
      },
      "source": [
        "We observe that the bigrams are similar across different topics but different across languages. Thus, the bigram frequency is a good feature for distinguishing languages, but not for distinguishing topics.\n",
        "\n",
        "Thus, we were able to convert a many-dimensional input (the text) to 26 dimesions (unigrams) or 26*26 dimensions (bigrams).\n",
        "\n",
        "\n",
        "A few ways to explore:\n",
        "1. Try with different languages.\n",
        "2. The topics we used are quite similar, wikipedia articles of 'elephant' and 'giraffe'. What happens if we use very different topics? What if we use text from another source than Wikipedia?\n",
        "3. How can we use and visualize trigrams and higher n-grams?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZJfjIHk-oHV"
      },
      "source": [
        "# Part 2: Written numbers\n",
        "\n",
        "We will use a subset of the MNIST dataset. Each input character is represented in a 28*28 array. Let us see if we can extract some simple features from these images which can help us distinguish between the digits.\n",
        "\n",
        "Load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNsLJSr6wGY0"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "#loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVNr144WAUZO"
      },
      "source": [
        "Extract a subset of the data for our experiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3MN8ddxAASZ"
      },
      "source": [
        "no1 = train_X[train_y==1,:,:]\n",
        "no0 = train_X[train_y==0,:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePXCs0qyCLpc"
      },
      "source": [
        "Let us visualize a few images here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQeyZSh-Arpc"
      },
      "source": [
        "for ii in range(5):\n",
        "  plt.subplot(1, 5, ii+1)\n",
        "  plt.imshow(no1[ii,:,:])\n",
        "plt.show()\n",
        "for ii in range(5):\n",
        "  plt.subplot(1, 5, ii+1)\n",
        "  plt.imshow(no0[ii,:,:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-Tg7EKDz96"
      },
      "source": [
        "suNow, let us start with a simple feature: the sum of all pixels and see how good this feature is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8SztDk7CyZc"
      },
      "source": [
        "sum1 = np.sum(no1>0, (1,2)) # threshold before adding up\n",
        "sum0 = np.sum(no0>0, (1,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oW3XCOCE7Zv"
      },
      "source": [
        "Let us visualize how good this feature is: (X-axis is mean, y-axis is the digit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8PIe8o_DPpU"
      },
      "source": [
        "plt.hist(sum1, alpha=0.7);\n",
        "plt.hist(sum0, alpha=0.7);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_hToEepFtl2"
      },
      "source": [
        "We can already see that this feature separates the two classes quite well.\n",
        "\n",
        "Let us look at another, more complicated feature. We will count the number black pixels that are surrounded on four sides by non-black pixels, or \"hole pixels\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwEnlm6RFFej"
      },
      "source": [
        "def cumArray(img):\n",
        "  img2 = img.copy()\n",
        "  for ii in range(1, img2.shape[1]):\n",
        "    img2[ii,:] = img2[ii,:] + img2[ii-1,:]  # for every row, add up all the rows above it.\n",
        "  img2 = img2>0\n",
        "  return img2\n",
        "\n",
        "def getHolePixels(img):\n",
        "  im1 = cumArray(img)\n",
        "  im2 = np.rot90(cumArray(np.rot90(img)), 3) # rotate and cumulate it again for differnt direction\n",
        "  im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "  im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "  hull =  im1 & im2 & im3 & im4 # this will create a binary image with all the holes filled in.\n",
        "  hole = hull & ~ (img>0) # remove the original digit to leave behind the holes\n",
        "  return hole"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw3HjgnupUEI"
      },
      "source": [
        "Visualize a few:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0sjr23NYEFe"
      },
      "source": [
        "imgs = [no1[456,:,:],  no0[456,:,:]]\n",
        "for img in imgs:\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(getHolePixels(img))\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS-4erNXtxMi"
      },
      "source": [
        "Now let us plot the number of hole pixels and see how this feature behaves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpm1dRgsety8"
      },
      "source": [
        "hole1 = np.array([getHolePixels(i).sum() for i in no1])\n",
        "hole0 = np.array([getHolePixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(hole1, alpha=0.7);\n",
        "plt.hist(hole0, alpha=0.7);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjCBHpJ31yq"
      },
      "source": [
        "This feature works even better to distinguish between one and zero.\n",
        "\n",
        "\n",
        "Now let us try the number of pixels in the 'hull' or the number with the holes filled in:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPtJ8eqolAOf"
      },
      "source": [
        "def getHullPixels(img):\n",
        "  im1 = cumArray(img)\n",
        "  im2 = np.rot90(cumArray(np.rot90(img)), 3) # rotate and cumulate it again for differnt direction\n",
        "  im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "  im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "  hull =  im1 & im2 & im3 & im4 # this will create a binary image with all the holes filled in.\n",
        "  return hull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3fOgyYjmJ48"
      },
      "source": [
        "imgs = [no1[456,:,:],  no0[456,:,:]]\n",
        "for img in imgs:\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(getHullPixels(img))\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5rHal_HRWnE"
      },
      "source": [
        "Plotting the number of hull pixels versus the digit:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTLzYZLTRQ_p"
      },
      "source": [
        "hull1 = np.array([getHullPixels(i).sum() for i in no1])\n",
        "hull0 = np.array([getHullPixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(hull1, alpha=0.7);\n",
        "plt.hist(hull0, alpha=0.7);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSzH26ElXNri"
      },
      "source": [
        "Let us try one more feature, where we look at the number of boundary pixels in each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-2czBypXMwT"
      },
      "source": [
        "def minus(a, b):\n",
        "  return a & ~ b\n",
        "\n",
        "def getBoundaryPixels(img):\n",
        "  img = img.copy()>0  # binarize the image\n",
        "  rshift = np.roll(img, 1, 1)\n",
        "  lshift = np.roll(img, -1 ,1)\n",
        "  ushift = np.roll(img, -1, 0)\n",
        "  dshift = np.roll(img, 1, 0)\n",
        "  boundary = minus(img, rshift) | minus(img, lshift) | minus(img, ushift) | minus(img, dshift)\n",
        "  return boundary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-V688jFerXh"
      },
      "source": [
        "imgs = [no1[456,:,:],  no0[456,:,:]]\n",
        "for img in imgs:\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(getBoundaryPixels(img))\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSsxsbCNXcNh"
      },
      "source": [
        "bound1 = np.array([getBoundaryPixels(i).sum() for i in no1])\n",
        "bound0= np.array([getBoundaryPixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(bound1, alpha=0.7);\n",
        "plt.hist(bound0, alpha=0.7);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuP04Ao_R0Yz"
      },
      "source": [
        "What will happen if we plot two features together?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl7xWg-WRkAy"
      },
      "source": [
        "# Sum and hull\n",
        "plt.scatter(sum0, hull0, alpha=0.1)\n",
        "plt.scatter(sum1, hull1, alpha=0.1)\n",
        "plt.xlabel('Sum')\n",
        "plt.ylabel('Hull')\n",
        "plt.legend(['0','1'])\n",
        "plt.show()\n",
        "\n",
        "# Sum and hole\n",
        "plt.scatter(sum0, hole0, alpha=0.1)\n",
        "plt.scatter(sum1, hole1, alpha=0.1)\n",
        "plt.xlabel('Sum');\n",
        "plt.ylabel('Hole');\n",
        "plt.legend(['0','1'])\n",
        "plt.show()\n",
        "\n",
        "# Hole and boundary\n",
        "plt.scatter(bound0, hole0, alpha=0.1)\n",
        "plt.scatter(bound1, hole1, alpha=0.1)\n",
        "plt.xlabel('Boundary');\n",
        "plt.ylabel('Hole');\n",
        "plt.legend(['0','1'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JYLmKNFSIT-"
      },
      "source": [
        "Now let us try plotting 3 features together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOKEHIXFaWp_"
      },
      "source": [
        "cl1 = ['class 1']*len(sum1)\n",
        "cl0 = ['class 0']*len(sum0)\n",
        "df = pd.DataFrame(list(zip(np.concatenate((hole0, hole0)), np.concatenate((sum1,sum0)),\n",
        "                           np.concatenate((bound1,bound0)), np.concatenate((cl1, cl0)))),\n",
        "               columns =['Hole', 'Sum', 'Boundary', 'Class'])\n",
        "df.head()\n",
        "fig = px.scatter_3d(df, x='Hole', y='Sum', z='Boundary', color='Class', opacity=0.1)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDGHlFSd5Fu"
      },
      "source": [
        "Feel free to explore the above graph with your mouse.\n",
        "\n",
        "\n",
        "We have seen that we extracted four features from a 28*28 dimensional image.\n",
        "\n",
        "\n",
        "Some questions to explore:\n",
        "1. Which is the best combination of features?\n",
        "2. How would you test or visualize four or more features?\n",
        "3. Can you come up with your own features?\n",
        "4. Will these features work for different classes other than 0 and 1?\n",
        "5. What will happen if we take more that two classes at a time?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question-1:**\n",
        "\n",
        ">To determine the best combination of features for your specific task,it's important to :\n",
        "\n",
        ">Understand the charcterstics of your data set(e.g.,text length,language diversity,topic diversity).\n",
        "\n",
        ">Experiment with different features combinations and models.\n",
        "\n",
        ">Use appropriate evaluation matrics(accuracy, F1-score, precision,recall,etc)to access model performance.\n",
        "\n",
        ">Consider cross-validation to ensure robustness and prevent overfitting."
      ],
      "metadata": {
        "id": "vgjW_mCe1KUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question-2:**\n",
        "\n",
        ">Testing and visualizing for or more features can be challenging due to the increased complexity of the dats.\n",
        "\n",
        ">However, there are serval techniques and tools you can use to effectively test and visualize multi-dimensional data."
      ],
      "metadata": {
        "id": "XDVDIEQD1MG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question-3:**\n",
        "\n",
        ">Certainly, when working with data analysis or machine learning tasks, you can create your own features through a process called featurea engineering.\n",
        "\n",
        ">Feature engineering involves designing and constructing new features from the existing data to improve the performance of a model or gain insights into the the dataset.\n",
        "\n",
        ">Here are some examples of how you can come up with your own feturea:text data time series data image data tabular data geosptial data audio data."
      ],
      "metadata": {
        "id": "Tt2pC6NK1M7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question-4:**\n",
        "\n",
        ">Yes, the features I mentioned can be used for classification problems with more than two class(i.e., classes other than 0 & 1).\n",
        "\n",
        ">The suitability of these features depends on the nature of your data specific classification task you're working on."
      ],
      "metadata": {
        "id": "6Si6f1N81N3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question-5:**\n",
        "\n",
        ">When you work with more than two classes in classification problems (often referred to as multi-class classification),several chnages and considerations come into play compared to binary classification(which involves only two classes, typically labled as 0 & 1)."
      ],
      "metadata": {
        "id": "jNyUgH1p1ujl"
      }
    }
  ]
}